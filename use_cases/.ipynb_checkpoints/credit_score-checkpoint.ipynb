{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc14dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from f2ai.common.collecy_fn import classify_collet_fn\n",
    "from f2ai.models.sequential import SimpleClassify\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from f2ai.featurestore import FeatureStore\n",
    "from f2ai.dataset import GroupFixednbrSampler\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fs = FeatureStore(\"file:///Users/xuyizhou/Desktop/xyz_warehouse/gitlab/f2ai-credit-scoring\")\n",
    "\n",
    "    ds = fs.get_dataset(\n",
    "        service=\"credit_scoring_v1\",\n",
    "        sampler=GroupFixednbrSampler(\n",
    "            time_bucket=\"10 days\",\n",
    "            stride=1,\n",
    "            group_ids=None,\n",
    "            group_names=None,\n",
    "            start=\"2020-08-01\",\n",
    "            end=\"2021-09-30\",\n",
    "        ),\n",
    "    )\n",
    "    features_cat = [  # catgorical features\n",
    "        fea\n",
    "        for fea in fs._get_feature_to_use(fs.services[\"credit_scoring_v1\"])\n",
    "        if fea not in fs._get_feature_to_use(fs.services[\"credit_scoring_v1\"], True)\n",
    "    ]\n",
    "    cat_unique = fs.stats(\n",
    "        fs.services[\"credit_scoring_v1\"],\n",
    "        fn=\"unique\",\n",
    "        group_key=[],\n",
    "        start=\"2020-08-01\",\n",
    "        end=\"2021-09-30\",\n",
    "        features=features_cat,\n",
    "    ).to_dict()\n",
    "    cat_count = {key: len(cat_unique[key]) for key in cat_unique.keys()}\n",
    "    cont_scalar_max = fs.stats(\n",
    "        fs.services[\"credit_scoring_v1\"], fn=\"max\", group_key=[], start=\"2020-08-01\", end=\"2021-09-30\"\n",
    "    ).to_dict()\n",
    "    cont_scalar_min = fs.stats(\n",
    "        fs.services[\"credit_scoring_v1\"], fn=\"min\", group_key=[], start=\"2020-08-01\", end=\"2021-09-30\"\n",
    "    ).to_dict()\n",
    "    cont_scalar = {key: [cont_scalar_min[key], cont_scalar_max[key]] for key in cont_scalar_min.keys()}\n",
    "\n",
    "    i_ds = ds.to_pytorch()\n",
    "    test_data_loader = DataLoader(  # `batch_siz`e and `drop_last`` do not matter now, `sampler`` set it to be None cause `test_data`` is a Iterator\n",
    "        i_ds,\n",
    "        collate_fn=lambda x: classify_collet_fn(\n",
    "            x,\n",
    "            cat_coder=cat_unique,\n",
    "            cont_scalar=cont_scalar,\n",
    "            label=fs._get_available_labels(fs.services[\"credit_scoring_v1\"]),\n",
    "        ),\n",
    "        batch_size=4,\n",
    "        drop_last=False,\n",
    "        sampler=None,\n",
    "    )\n",
    "\n",
    "    model = SimpleClassify(\n",
    "        cont_nbr=len(cont_scalar_max), cat_nbr=len(cat_count), emd_dim=4, max_types=max(cat_count.values())\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # no need to change\n",
    "    loss_fn = nn.BCELoss()  # loss function to train a classification model\n",
    "\n",
    "    for epoch in range(10):  # assume 10 epoch\n",
    "        print(f\"epoch: {epoch} begin\")\n",
    "        for x, y in test_data_loader:\n",
    "            pred_label = model(x)\n",
    "            true_label = y\n",
    "            loss = loss_fn(pred_label, true_label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: {epoch} done, loss: {loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autonn-3.8.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.7 (default, Dec 29 2021, 10:58:29) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5840e4ed671345474330e8fce6ab52c58896a3935f0e728b8dbef1ddfad82808"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
